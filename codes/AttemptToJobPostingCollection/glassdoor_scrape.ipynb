{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jul 10 23:24:20 2020\n",
    "\n",
    "@author: picklesueat\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  2 09:32:36 2020\n",
    "author: Kenarapfaik\n",
    "url: https://github.com/arapfaik/scraping-glassdoor-selenium\n",
    "\"\"\"\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Data Analyst'\n",
    "url = \"https://www.glassdoor.com/blog/tag/job-search/\"\n",
    "\n",
    "\n",
    "#Inputs keyword and loc, and bring you to the Job Listings\n",
    "def go_to_listings(driver, loc):\n",
    "\n",
    "       # wait for the search bar to appear\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='sc.keyword']\"))\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # look for search bar field\n",
    "        position_field = driver.find_element_by_xpath(\"//*[@id='sc.keyword']\")\n",
    "        location_field = driver.find_element_by_xpath(\"//*[@id='sc.location']\")\n",
    "        \n",
    "\n",
    "        # fill in with pre-defined data\n",
    "        position_field.clear()\n",
    "        position_field.send_keys(keyword)\n",
    "        \n",
    "        location_field.clear()\n",
    "        location_field.send_keys(loc)\n",
    "\n",
    "        # wait for a little so location gets set\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath(\" //*[@id='HeroSearchButton']\").click()\n",
    "\n",
    "        # close a random popup if it shows up\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='JAModal']/div/div[2]/span\").click()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "            \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='JAModal']/div/div[2]/span\").click()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "  \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "#Initializes driver, and navigates to URL\n",
    "def initialize_driver(path):\n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    \n",
    "    #makes the driver more 'undetectale'\n",
    "    options.add_argument(\"--disable-blink-features\"), options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "    \n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "\n",
    "def Xout_pop_ups(driver):\n",
    "        #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"selected\").click()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    #X out pop-up\n",
    "    try:\n",
    "        driver.find_element_by_css_selector('[alt=\"Close\"]').click() #clicking to the X.\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def click_listing(driver, job_button):\n",
    "    illstatus = 'Fine'\n",
    "    try:\n",
    "        job_button.click()#You might\n",
    "        \n",
    "    except Exception:\n",
    "        illstatus = 'Ill'\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            job_button.click()\n",
    "            illstatus = 'Illness Corrected'\n",
    "        except Exception:\n",
    "            illstatus = 'Failed'\n",
    "        \n",
    "    return illstatus\n",
    "        \n",
    "    \n",
    "def collect_listing_info(driver, slp_time, verbose):\n",
    "    time.sleep(slp_time)\n",
    "    collected_successfully = False\n",
    "    no_load_time = 0\n",
    "    while not collected_successfully:\n",
    "        #If page has timed out from not-loading, restart the process by clicking first listing\n",
    "\n",
    "        if(no_load_time >= 10):\n",
    "            driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li[1]\").click()\n",
    "\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='HeroHeaderModule']/div[3]/div[2]/div/div[1]/div[2]/button\")\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            no_load_time +=1\n",
    "        try:\n",
    "            company_name = driver.find_element_by_xpath('.//div[@class=\"employerName\"]').text\n",
    "            location = driver.find_element_by_xpath('.//div[@class=\"location\"]').text\n",
    "            job_title = driver.find_element_by_xpath('.//div[contains(@class, \"title\")]').text\n",
    "            job_description = driver.find_element_by_xpath('.//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "            collected_successfully = True\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        salary_estimate = driver.find_element_by_xpath('.//span[@class=\"gray salary\"]').text\n",
    "    except NoSuchElementException:\n",
    "        salary_estimate = -1 #You need to set a \"not found value. It's important.\"\n",
    "    \n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath('.//span[@class=\"rating\"]').text\n",
    "    except NoSuchElementException:\n",
    "        rating = -1 #You need to set a \"not found value. It's important.\"\n",
    "\n",
    "    #Printing for debugging\n",
    "    if verbose:\n",
    "        print(\"Job Title: {}\".format(job_title))\n",
    "        print(\"Salary Estimate: {}\".format(salary_estimate))\n",
    "        print(\"Job Description: {}\".format(job_description[:500]))\n",
    "        print(\"Rating: {}\".format(rating))\n",
    "        print(\"Company Name: {}\".format(company_name))\n",
    "        print(\"Location: {}\".format(location))\n",
    "\n",
    "    #Going to the Company tab...\n",
    "    #clicking on this:\n",
    "    #<div class=\"tab\" data-tab-type=\"overview\"><span>Company</span></div>\n",
    "    try:\n",
    "        driver.find_element_by_xpath('.//div[@class=\"tab\" and @data-tab-type=\"overview\"]').click()\n",
    "\n",
    "        try:\n",
    "            #<div class=\"infoEntity\">\n",
    "            #    <label>Headquarters</label>\n",
    "            #    <span class=\"value\">San Francisco, CA</span>\n",
    "            #</div>\n",
    "            headquarters = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Headquarters\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            headquarters = -1\n",
    "\n",
    "        try:\n",
    "            size = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Size\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            size = -1\n",
    "\n",
    "        try:\n",
    "            founded = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Founded\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            founded = -1\n",
    "\n",
    "        try:\n",
    "            type_of_ownership = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Type\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            type_of_ownership = -1\n",
    "\n",
    "        try:\n",
    "            industry = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Industry\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            industry = -1\n",
    "\n",
    "        try:\n",
    "            sector = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Sector\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            sector = -1\n",
    "\n",
    "        try:\n",
    "            revenue = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Revenue\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            revenue = -1\n",
    "\n",
    "        try:\n",
    "            competitors = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Competitors\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            competitors = -1\n",
    "\n",
    "        \n",
    "        try:\n",
    "            easy_apply = (driver.find_element_by_xpath('//*[@id=\"HeroHeaderModule\"]/div[3]/div[2]/div/div[1]/div[1]/button/span').text  == 'Easy Apply')\n",
    "        except NoSuchElementException:\n",
    "            easy_apply = -1\n",
    "\n",
    "    except NoSuchElementException:  #Rarely, some job postings do not have the \"Company\" tab.\n",
    "        headquarters = -1\n",
    "        size = -1\n",
    "        founded = -1\n",
    "        type_of_ownership = -1\n",
    "        industry = -1\n",
    "        sector = -1\n",
    "        revenue = -1\n",
    "        competitors = -1\n",
    "        easy_apply = -1\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Headquarters: {}\".format(headquarters))\n",
    "        print(\"Size: {}\".format(size))\n",
    "        print(\"Founded: {}\".format(founded))\n",
    "        print(\"Type of Ownership: {}\".format(type_of_ownership))\n",
    "        print(\"Industry: {}\".format(industry))\n",
    "        print(\"Sector: {}\".format(sector))\n",
    "        print(\"Revenue: {}\".format(revenue))\n",
    "        print(\"Competitors: {}\".format(competitors))\n",
    "        print(\"Easy Apply: {}\".format(easy_apply))\n",
    "        print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "    jobinfo = ({\"Job Title\" : job_title,\n",
    "    \"Salary Estimate\" : salary_estimate,\n",
    "    \"Job Description\" : job_description,\n",
    "    \"Rating\" : rating,\n",
    "    \"Company Name\" : company_name,\n",
    "    \"Location\" : location,\n",
    "    \"Headquarters\" : headquarters,\n",
    "    \"Size\" : size,\n",
    "    \"Founded\" : founded,\n",
    "    \"Type of ownership\" : type_of_ownership,\n",
    "    \"Industry\" : industry,\n",
    "    \"Sector\" : sector,\n",
    "    \"Revenue\" : revenue,\n",
    "    \"Competitors\" : competitors,\n",
    "    \"Easy Apply\": easy_apply})\n",
    "    \n",
    "    return jobinfo\n",
    "\n",
    "\n",
    "\n",
    "def make_sure_jobs(driver):\n",
    "    try:\n",
    "        if(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div[1]/p/span[2]\").text.split(' ' )[1] == 'search'):\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            if(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div[1]/p/span[2]\").text.split(' ' )[1] == 'search'):\n",
    "                return 'X'\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        print(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1])\n",
    "        if((driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1] == 'search')):\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            if((driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1] == 'search')):\n",
    "                return 'X'\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "def get_jobs(keyword, num_jobs, verbose, path, slp_time, loc = ' ', driver = ' '):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from Glassdoor'''\n",
    "    \n",
    "    count = 0 \n",
    "\n",
    "    if(loc == ' '):\n",
    "        driver = initialize_driver(path)\n",
    "    \n",
    "    driver.get(url)\n",
    "    go_to_listings(driver,loc)\n",
    "           \n",
    "    \n",
    "    jobs = []\n",
    "\n",
    "    while len(jobs) < num_jobs:  #If true, should be still looking for new jobs.\n",
    "\n",
    "        #Let the page load. Change this number based on your internet speed.\n",
    "        #Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='HeroSearchButton']\"))\n",
    "        )\n",
    "\n",
    "\n",
    "        #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "        Xout_pop_ups(driver)\n",
    "\n",
    "        x = make_sure_jobs(driver)\n",
    "        if(x == 'X'):\n",
    "            break\n",
    "\n",
    "        #Going through each job in this page\n",
    "        time.sleep(1.5)\n",
    "        job_buttons = driver.find_elements_by_css_selector(\"li.jl.react-job-listing.gdGrid\")  #jl for Job Listing. These are the buttons we're going to click.\n",
    "        if(len(job_buttons) <=25):\n",
    "            print(\"JOBS PER PAGE: \" + str(len(job_buttons)))\n",
    "        for job_button in job_buttons: \n",
    "            if len(jobs) >= num_jobs:\n",
    "                print(\"Job Target Reached:\" + str(len(jobs)) + '/' + str(num_jobs))\n",
    "                break\n",
    "\n",
    "            status = click_listing(driver, job_button)\n",
    "\n",
    "            #Weird error pops up here, so I'm on the lookout,\n",
    "            if(status == 'Failed'):\n",
    "                print(status)\n",
    "                break\n",
    "\n",
    "            #append listing data, to total list for that location \n",
    "            jobs.append(collect_listing_info(driver, slp_time, verbose = verbose))\n",
    "\n",
    "        page_num = driver.find_element_by_xpath(\"//*[@id='ResultsFooter']/div[1]\").text\n",
    "        page_num = page_num.split(' ')\n",
    "        if(page_num[1] == page_num[3]):\n",
    "            break\n",
    "        \n",
    "        #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            if(count<=33):\n",
    "                driver.find_element_by_xpath('.//li[@class=\"next\"]//a').click()\n",
    "                count +=1\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(jobs)  #This line converts the dictionary object into a pandas DataFrame.\n",
    "\n",
    "\n",
    "def page_limit(keyword, num_jobs, verbose, path, slp_time, start_at = 0):\n",
    "    driver = initialize_driver(path)\n",
    "    #General Location\n",
    "    if(start_at == 0):\n",
    "        df = get_jobs(keyword, 1, verbose, path, slp_time)\n",
    "        df = df[0:0]\n",
    "        df.to_csv('glassdoor_job_data/' + keyword.replace(' ', '') + '.csv', index = False)\n",
    "    \n",
    "    cities = top_cities()\n",
    "    \n",
    "    for x in range(start_at,len(cities.index) - 217):\n",
    "        print(\"City Index: \" + str(x))\n",
    "        try:    \n",
    "            df = get_jobs(keyword, num_jobs, verbose, path, slp_time, loc = (cities.iloc[x,0] + ', ' + cities.iloc[x,1]), driver = driver)\n",
    "        except Exception:\n",
    "            print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            df = get_jobs(keyword, num_jobs, verbose, path, slp_time, loc = (cities.iloc[x,0] + ', ' + cities.iloc[x,1]), driver = driver)\n",
    "        df.to_csv('glassdoor_job_data/' + keyword.replace(' ', '') + '.csv', index = False, mode='a', header=False)\n",
    "\n",
    "\n",
    "\n",
    "def top_cities():\n",
    "    #scrapes the list of most populated cities from wikipedia\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    table = soup.find('table',{'class':'wikitable sortable'})\n",
    "    rows = (table.find_all('tr'))\n",
    "    \n",
    "    city = []\n",
    "    state = []\n",
    "    df = pd.DataFrame()\n",
    "    rows.pop(0)\n",
    "    for row in rows: \n",
    "        data = row.find_all('a')\n",
    "        city.append(data[0].text)\n",
    "        state.append(row.find_all('td')[2].text.replace('\\n',''))\n",
    "        \n",
    "    city = pd.Series(city)\n",
    "    state = pd.Series(state)\n",
    "    df['City'] = city\n",
    "    df['State'] = state\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#to test program    \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m page_limit(keyword, \u001b[39m500\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39m\"\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mProgram Files (x86)\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mchromedriver_win32\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mchromedriver.exe\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m2.5\u001b[39;49m, start_at \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[13], line 351\u001b[0m, in \u001b[0;36mpage_limit\u001b[1;34m(keyword, num_jobs, verbose, path, slp_time, start_at)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39m#General Location\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39mif\u001b[39;00m(start_at \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m--> 351\u001b[0m     df \u001b[39m=\u001b[39m get_jobs(keyword, \u001b[39m1\u001b[39;49m, verbose, path, slp_time)\n\u001b[0;32m    352\u001b[0m     df \u001b[39m=\u001b[39m df[\u001b[39m0\u001b[39m:\u001b[39m0\u001b[39m]\n\u001b[0;32m    353\u001b[0m     df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mglassdoor_job_data/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m keyword\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[13], line 298\u001b[0m, in \u001b[0;36mget_jobs\u001b[1;34m(keyword, num_jobs, verbose, path, slp_time, loc, driver)\u001b[0m\n\u001b[0;32m    291\u001b[0m jobs \u001b[39m=\u001b[39m []\n\u001b[0;32m    293\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(jobs) \u001b[39m<\u001b[39m num_jobs:  \u001b[39m#If true, should be still looking for new jobs.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \n\u001b[0;32m    295\u001b[0m     \u001b[39m#Let the page load. Change this number based on your internet speed.\u001b[39;00m\n\u001b[0;32m    296\u001b[0m     \u001b[39m#Or, wait until the webpage is loaded, instead of hardcoding it.\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     element \u001b[39m=\u001b[39m WebDriverWait(driver, \u001b[39m30\u001b[39;49m)\u001b[39m.\u001b[39;49muntil(\n\u001b[0;32m    299\u001b[0m         EC\u001b[39m.\u001b[39;49mpresence_of_element_located((By\u001b[39m.\u001b[39;49mXPATH, \u001b[39m\"\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHeroSearchButton\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    303\u001b[0m     \u001b[39m#Test for the \"Sign Up\" prompt and get rid of it.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     Xout_pop_ups(driver)\n",
      "File \u001b[1;32md:\\Program Files (x86)\\Anaconda\\envs\\anly645\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py:80\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m end_time:\n\u001b[0;32m     79\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[39mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "#to test program    \n",
    "page_limit(keyword, 500, True, \"D:\\Program Files (x86)\\chromedriver_win32\\chromedriver.exe\", 2.5, start_at = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anly645",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
